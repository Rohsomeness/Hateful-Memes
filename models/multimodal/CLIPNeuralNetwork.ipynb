{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLIPNeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohsomeness/Hateful-Memes/blob/main/models/multimodal/CLIPNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxFe-jcmS0YP"
      },
      "source": [
        "Copy test.jsonl over for testing on test_seen ground truth(obtained from https://hatefulmemeschallenge.com/)\n",
        "-Mario Goranov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra1GynMjRKxK"
      },
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "resultTest = [json.loads(jline) for jline in open('/content/test.jsonl', 'r')]\n",
        "print(len(resultTest))\n",
        "resultTensor = torch.zeros(len(resultTest))\n",
        "for i in range(len(resultTest)):\n",
        "  resultTensor[i] = resultTest[i]['label']\n",
        "print(resultTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34A2m0RCh1Cz"
      },
      "source": [
        "Using preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp1TC7tsSRzu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls '/gdrive/MyDrive/MemesDeepLearning'\n",
        "!cp '/gdrive/MyDrive/MemesDeepLearning/tensorDataPreprocessed.zip' '/content/tensorData.zip'\n",
        "!unzip -q tensorData.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6N5SvnNh2Kr"
      },
      "source": [
        "Using nonpreprocessed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJk8ZzC4iai1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls '/gdrive/MyDrive/MemesDeepLearning'\n",
        "!cp '/gdrive/MyDrive/MemesDeepLearning/tensorData.zip' '/content/tensorData.zip'\n",
        "!cp '/gdrive/MyDrive/MemesDeepLearning/tensorDataTestOnly.zip' '/content/tensorDataTestOnly.zip'\n",
        "!unzip -q tensorData.zip\n",
        "!unzip tensorDataTestOnly.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjCLLS_PSzz0"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxXF_NHpSl6L"
      },
      "source": [
        "%cd newData\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "trainDataGround = []\n",
        "trainDataImg = []\n",
        "trainDataText = []\n",
        "testDataGround = []\n",
        "testDataImg = []\n",
        "testDataText = []\n",
        "\n",
        "finalTestImg = []\n",
        "finalTestText = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(8):\n",
        "    trainDataGround.append(torch.load(f'train_truth_{i}.pt'))\n",
        "    trainDataImg.append(torch.load(f'train_img_{i}.pt'))\n",
        "    trainDataText.append(torch.load(f'train_txt_{i}.pt'))\n",
        "    testDataGround.append(torch.load(f'dev_truth_{i}.pt'))\n",
        "    testDataImg.append(torch.load(f'dev_img_{i}.pt'))\n",
        "    testDataText.append(torch.load(f'dev_txt_{i}.pt'))\n",
        "    finalTestImg.append(torch.load(f'test1_img_{i}.pt'))\n",
        "    finalTestText.append(torch.load(f'test1_txt_{i}.pt'))\n",
        "\n",
        "\n",
        "train_ground = np.concatenate(trainDataGround)\n",
        "train_img = torch.cat(trainDataImg)\n",
        "train_text = torch.cat(trainDataText)\n",
        "\n",
        "test_ground = np.concatenate(testDataGround)\n",
        "test_img = torch.cat(testDataImg)\n",
        "test_text = torch.cat(testDataText)\n",
        "\n",
        "final_test_img = torch.cat(finalTestImg)\n",
        "final_test_text = torch.cat(finalTestText)\n",
        "\n",
        "train_ground = torch.from_numpy(train_ground)\n",
        "#train_img = torch.from_numpy(train_img)\n",
        "#train_text = torch.from_numpy(train_text)\n",
        "\n",
        "test_ground = torch.from_numpy(test_ground)\n",
        "#test_img = torch.from_numpy(test_img)\n",
        "#test_text = torch.from_numpy(test_text)\n",
        "\n",
        "train_data = torch.cat([train_img,train_text],dim=1)\n",
        "test_data = torch.cat([test_img,test_text],dim=1)\n",
        "final_test_data = torch.cat([final_test_img,final_test_text],dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7X0c0Xg-FrX"
      },
      "source": [
        "batch_size = 32\n",
        "train_data_batched = torch.split(train_data,batch_size)\n",
        "train_ground_batched = torch.split(train_ground,batch_size)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(final_test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_5lK9gsAP8A"
      },
      "source": [
        "bestAccuracy = 0\n",
        "bestModel = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnnXCUZfhgE-"
      },
      "source": [
        "None of these were eventually used and can be ignored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm2ksRp6YF9N"
      },
      "source": [
        "class MemeModel(nn.Module):\n",
        "    \"\"\"Some Information about MemeModel\"\"\"\n",
        "    def __init__(self):\n",
        "        super(MemeModel, self).__init__()\n",
        "        innerSize = 32\n",
        "        self.linear1 = nn.Linear(1024,innerSize)\n",
        "        \n",
        "        self.linear2 = nn.Linear(innerSize,innerSize)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        #self.batch1 = nn.BatchNorm1d(innerSize)\n",
        "        self.linear3 = nn.Linear(innerSize,innerSize)\n",
        "        #self.batch2 = nn.BatchNorm1d(innerSize)\n",
        "\n",
        "        self.linear4 = nn.Linear(innerSize,2)\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        #x = self.batch1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        oldX = x\n",
        "        x = self.linear2(x)\n",
        "        #x = self.batch1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear3(x)\n",
        "        #x = self.batch2(x)\n",
        "\n",
        "        x = x + oldX\n",
        "        \n",
        "        x = F.relu(x)\n",
        "        x = self.linear4(x)\n",
        "\n",
        "        #x = self.softmax(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEXN8u9b40y5"
      },
      "source": [
        "class QuickModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(QuickModel, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=0.5)\n",
        "    self.linear1 = nn.Linear(1024,1024*(2**5))\n",
        "    self.linear2 = nn.Linear(1024*(2**5),64)\n",
        "    self.linear3 = nn.Linear(64,2)\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear3(x)\n",
        "    #x = F.sigmoid(x)\n",
        "    #x = F.softmax(x,dim=1)\n",
        "    #x = F.relu(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90pP2IZQL2Md"
      },
      "source": [
        "class QuickerModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(QuickerModel, self).__init__()\n",
        "    innerSize = 128\n",
        "    self.numInner = 1\n",
        "    self.linear1 = nn.Linear(1024,innerSize)\n",
        "    self.linear = nn.ModuleList([nn.Linear(innerSize, innerSize) for i in range(self.numInner)])\n",
        "    self.linear2 = nn.Linear(innerSize,2)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    for module in self.linear:\n",
        "      x = module(x)\n",
        "      x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVFTipHAB2em"
      },
      "source": [
        "import random\n",
        "\n",
        "class Shift(nn.Module):\n",
        "  def __init__(self, shiftAmount):\n",
        "    super(Shift, self).__init__()\n",
        "    self.shiftAmount = shiftAmount\n",
        "  def forward(self, x):\n",
        "    torch.roll(x, random.randrange(-self.shiftAmount,self.shiftAmount,1)*self.training, dims=1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stl5CJqzEe7g"
      },
      "source": [
        "class ShiftModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ShiftModel, self).__init__()\n",
        "    self.linear1 = nn.Linear(1024,1024)\n",
        "    #self.shift = Shift(0)\n",
        "    self.linear2 = nn.Linear(1024,2)\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    #x = self.shift(x)\n",
        "    x = self.linear2(x)\n",
        "    #x = F.sigmoid(x)\n",
        "    #x = F.softmax(x,dim=1)\n",
        "    #x = F.relu(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RZsU4KIYHxa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#model = QuickModel()\n",
        "model = nn.Sequential(\n",
        "    nn.Dropout(p=0.5),\n",
        "    nn.Linear(1024,1024*2**5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024*2**5,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64,2)\n",
        ")\n",
        "\n",
        "EPOCHS = 200\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "#optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "\n",
        "#scaler = torch.Tensor([0.75,1])\n",
        "\n",
        "\n",
        "runLoss = []\n",
        "runAcc = []\n",
        "maxAccTemp = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i in range(len(train_data_batched)):\n",
        "        \n",
        "        inputs = train_data_batched[i].to(device)\n",
        "        labels = train_ground_batched[i].type(torch.LongTensor).to(device)\n",
        "        \n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        #print(outputs.dtype)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        howOften = len(train_data_batched)\n",
        "        if i % howOften == howOften-1:\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            numCorrect = (predicted == labels).sum().item()\n",
        "            acc = (100.0 * numCorrect / labels.shape[0])\n",
        "            #print(outputs)\n",
        "            #print(labels)\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_data = test_data.to(device)\n",
        "                test_ground = test_ground.to(device)\n",
        "                outputs = model(test_data)\n",
        "                #print(test_data.shape)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                numCorrect = (predicted == test_ground).sum().item()\n",
        "                acc2 = (100.0 * numCorrect / test_data.shape[0])\n",
        "                runAcc.append(acc2)\n",
        "                if acc2>maxAccTemp:\n",
        "                  maxAccTemp = acc2\n",
        "                if acc2>bestAccuracy:\n",
        "                  print(f\"This is BETTER than the old model which has {bestAccuracy}%\")\n",
        "                  bestAccuracy = acc2\n",
        "                  bestModel = copy.deepcopy(model)\n",
        "                #print('Accuracy of the network on the test data: %f %%' % acc2)\n",
        "                print('[%d, %5d] loss: %.3f %.1f%% %.5f%%' %\n",
        "                  (epoch + 1, i + 1, running_loss / howOften, acc, acc2))\n",
        "                #print(f\"Current best: {bestAccuracy} %\")\n",
        "            model.train()\n",
        "            runLoss.append(running_loss / howOften)\n",
        "            running_loss = 0.0\n",
        "    #scheduler.step()\n",
        "print(f'Finished Training with max acc {maxAccTemp}%')\n",
        "print(model)\n",
        "fig, ax_left = plt.subplots()\n",
        "ax_right = ax_left.twinx()\n",
        "\n",
        "ax_left.plot(runLoss, color='black')\n",
        "ax_right.plot(runAcc, color='red')\n",
        "\n",
        "ax_left.set_ylabel(\"Loss\", color='black')\n",
        "ax_right.set_ylabel(\"Acc\", color='red')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZ5ZlaCWapt"
      },
      "source": [
        "Validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1PbMgkZYJmk"
      },
      "source": [
        "\n",
        "#model = bestModel\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_data = test_data.to(device)\n",
        "    test_ground = test_ground.to(device)\n",
        "    outputs = model(test_data)\n",
        "    print(test_data.shape)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    numCorrect = (predicted == test_ground).sum().item()\n",
        "    acc = (100.0 * numCorrect / test_data.shape[0])\n",
        "    if acc>bestAccuracy:\n",
        "      print(f\"This is BETTER than the old model which has {bestAccuracy}%\")\n",
        "      bestAccuracy = acc\n",
        "      bestModel = model\n",
        "    print('Accuracy of the network on the test data: %f %%' % acc)\n",
        "    print(f\"Current best: {bestAccuracy} %\")\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKA9GA8Wzsf_"
      },
      "source": [
        "Test_seen: Generate submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAXn8JwoeZd1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "model# = bestModel\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    final_test_data = final_test_data.to(device)\n",
        "    outputs = model(final_test_data)\n",
        "    outputs = F.softmax(outputs,dim=1)\n",
        "    first, predicted = torch.max(outputs.data, 1)\n",
        "    resultTensor = resultTensor.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "\n",
        "    \n",
        "    numCorrect = (predicted == resultTensor).sum().item()\n",
        "    acc = (100.0 * numCorrect / resultTensor.shape[0])\n",
        "    \n",
        "    probs = outputs[:,1].cpu().numpy()\n",
        "    print(predicted)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(resultTensor, probs, pos_label=1)\n",
        "    auroc = metrics.auc(tpr, fpr)\n",
        "    plt.scatter(fpr,tpr)\n",
        "    plt.xlabel(\"False positive rate\")\n",
        "    plt.ylabel(\"True positive rate\")\n",
        "    plt.show()\n",
        "    print(f\"Accuracy: {acc} AUROC: {auroc}\")\n",
        "    with open(\"/content/submission1.csv\", \"w\") as f:\n",
        "      f.write(\"proba,label\\n\")\n",
        "      for i in range(predicted.shape[0]):\n",
        "        f.write(f\"{outputs[:,1][i]},{predicted[i]}\\n\")\n",
        "model.train()\n",
        "print(bestModel)\n",
        "print(optimizer)\n",
        "print(f\"Batch size {batch_size}\")\n",
        "print(f\"# of epochs {EPOCHS}\")\n",
        "print(f\"Validation accuracy {bestAccuracy}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SCJ5_9DhrB5"
      },
      "source": [
        "Save models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd6DWRhp5XXl"
      },
      "source": [
        "torch.save(bestModel,'/content/bestModelWithoutPrepro.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IcTZHUS9b_f"
      },
      "source": [
        "model = torch.load('/content/bestModel.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYylj47TZssa"
      },
      "source": [
        "print(newBestTest)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}